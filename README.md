# Bias Injection Simulator â€” Stress-Testing ML Fairness

## ðŸ§  CORE VISION

Build a **Bias Injection Simulator** that intentionally injects controlled bias into datasets to **observe, quantify, and visualize how ML models degrade, discriminate, or collapse** under biased conditions.

This is not a bias detector.
This is a **bias weaponization lab**.

The product feels like:
* A **scientific experiment**
* A **mission control dashboard**
* A **data ethics war room**

---

## ðŸŽ¯ OBJECTIVES

1. Allow users to **inject different bias types** into a clean dataset.
2. Train ML models **before and after bias injection**.
3. Measure **performance decay + fairness collapse**.
4. Visually show **where, how, and why models break**.
5. Rank models by **bias resilience**, not just accuracy.

---

## ðŸ§¬ BIAS TYPES SUPPORTED

* **Sampling Bias**: Over/under-represent specific groups
* **Label Bias**: Flip labels for specific demographics
* **Feature Proxy Bias**: Introduce proxy variables (ZIP â†’ income)
* **Historical Bias**: Replay past discriminatory patterns
* **Measurement Bias**: Add systematic noise to features

---

## ðŸ§± TECH STACK

* **Backend**: Python + FastAPI
* **ML**: scikit-learn, XGBoost, SHAP, Fairlearn
* **Frontend**: Next.js (React)
* **3D**: Three.js / React Three Fiber
* **Charts**: D3.js / Recharts
- Implemented Holographic Background
- Added CyberSphere 3D Component
- Refactored Global Layout
